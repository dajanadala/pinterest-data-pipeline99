{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook displays the cleaning transformations and querying operations performed on a spark cluster in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task was first done by using some basic EDA such as checking for duplicates, null values, taking value counts and using.describe() etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "\n",
    "display(df_pin)\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"description\",\n",
    "    when(\n",
    "        (df_pin.description == \"Untitled\") |\n",
    "        (df_pin.description == \"No description available\") |\n",
    "        (df_pin.description == \"No description available Story format\"),\n",
    "        \"None\"\n",
    "    ).otherwise(df_pin.description)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"tag_list\",\n",
    "    when(\n",
    "        (df_pin.tag_list == \"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\")|\n",
    "        (df_pin.tag_list == \"0\"),\n",
    "        \"None\"\n",
    "    ).otherwise(df_pin.tag_list)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"title\",\n",
    "    when(\n",
    "        (df_pin.title == \"No Title Data Available\"),\n",
    "        \"None\"\n",
    "    ).otherwise(df_pin.title)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"k\", \"000\"))\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"M\", \"000000\"))\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(\n",
    "        (df_pin.follower_count == \"User Info Error\"),\n",
    "        \"0\"\n",
    "    ).otherwise(df_pin.follower_count)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"image_src\",\n",
    "    when(\n",
    "        (df_pin.image_src == \"Image src error.\"),\n",
    "        \"None\"\n",
    "    ).otherwise(df_pin.image_src)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"poster_name\",\n",
    "    when(\n",
    "        (df_pin.poster_name == \"User Info Error\"),\n",
    "        \"None\"\n",
    "    ).otherwise(df_pin.poster_name)\n",
    ")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"downloaded\",\n",
    "    when(\n",
    "        (df_pin.downloaded == \"None\"),\n",
    "        \"0\"\n",
    "    ).otherwise(df_pin.downloaded)\n",
    ")\n",
    "\n",
    "\n",
    "# change the datatype of the \"follower_count\" column to int\n",
    "df_pin = df_pin.withColumn(\"follower_count\", col(\"follower_count\").cast(\"int\"))\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "\n",
    "df_pin = df_pin.withColumn(\"save_location\", regexp_replace(\"save_location\", \"Local save in \", \"\"))\n",
    "\n",
    "\n",
    "df_pin = df_pin.select(col(\"ind\"), col(\"unique_id\"), col(\"title\"), col(\"description\"), col(\"follower_count\"), col(\"poster_name\"), col(\"tag_list\"), col(\"is_image_or_video\"), col(\"image_src\"), col(\"save_location\"), col(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array\n",
    "\n",
    "display(df_geo)\n",
    "\n",
    "\n",
    "df_geo = df_geo.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "\n",
    "\n",
    "df_geo = df_geo.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "\n",
    "# change the datatype of the \"timestamp\" column to timestamp\n",
    "df_geo = df_geo.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "\n",
    "df_geo = df_geo.select(col(\"ind\"), col(\"country\"), col(\"coordinates\"), col(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "\n",
    "\n",
    "display(df_user)\n",
    "\n",
    "\n",
    "df_user = df_user.withColumn('user_name', concat(df_user.first_name, df_user.last_name))\n",
    "\n",
    "\n",
    "df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "\n",
    "# change the datatype of the \"date_joined\" column to timestamp\n",
    "df_user = df_user.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\"))\n",
    "\n",
    "\n",
    "df_user = df_user.select(col(\"ind\"), col(\"user_name\"), col(\"age\"), col(\"date_joined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. Find the most popular category people post to based on their country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc, struct\n",
    "\n",
    "df_most_popular_category_by_country = df_pin.join(df_geo, on='ind') \\\n",
    "       .groupBy('country', 'category') \\\n",
    "       .agg(count('*').alias('count')) \\\n",
    "       .groupBy('country') \\\n",
    "       .agg(max(struct('count', 'category')).alias('max_count')) \\\n",
    "       .select('country', 'max_count.category', 'max_count.count') \\\n",
    "       .withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "df_most_popular_category_by_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. Find which was the most popular category each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Join df_pin with df_geo on the 'ind' column and filter by timestamp range\n",
    "df_most_popular_category_by_year = df_pin.join(df_geo, on='ind') \\\n",
    "    .filter((year('timestamp') >= 2018) & (year('timestamp') <= 2022))\n",
    "\n",
    "# Group by year and category, and count the number of occurrences\n",
    "df_most_popular_category_by_year = df_most_popular_category_by_year.groupBy(year('timestamp').alias('post_year'), 'category') \\\n",
    "       .agg(count('*').alias('category_count'))\n",
    "\n",
    "# Find the most popular category for each year\n",
    "df_most_popular_category_by_year = df_most_popular_category_by_year.orderBy(['post_year', 'category_count'], ascending=[True, False]) \\\n",
    "    .groupBy('post_year') \\\n",
    "    .agg({'category': 'first', 'category_count': 'first'}) \\\n",
    "    .withColumnRenamed('first(category)', 'category') \\\n",
    "    .withColumnRenamed('first(category_count)', 'category_count')\n",
    "\n",
    "# Show the result\n",
    "df_most_popular_category_by_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3. Find the user with the most followers in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Find the user with the most followers in each country\n",
    "df_most_followers_by_country = df_pin.join(df_geo, on='ind') \\\n",
    "      .groupBy('country', 'poster_name') \\\n",
    "      .agg(max('follower_count')) \\\n",
    "      .withColumn('rank', rank().over(Window.partitionBy('country').orderBy(desc('max(follower_count)')))) \\\n",
    "      .filter('rank = 1') \\\n",
    "      .select('country', 'poster_name', 'max(follower_count)') \\\n",
    "      .withColumnRenamed('max(follower_count)', 'follower_count')\n",
    "\n",
    "df_most_followers_by_country.show()\n",
    "\n",
    "# Find the country with the user that has the most followers\n",
    "df_most_followers_country = df_most_followers_by_country.groupBy('country') \\\n",
    "      .agg(max('follower_count').alias('follower_count')) \\\n",
    "      .orderBy(desc('follower_count')) \\\n",
    "      .limit(1) \\\n",
    "      .select('country', 'follower_count')\n",
    "\n",
    "df_most_followers_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4. Find the most popular category for different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_user_with_age_group = df_pin.join(df_user, on=\"ind\") \\\n",
    "    .withColumn(\"age_group\", \n",
    "                when(df_user.age.between(18, 24), \"18-24\")\n",
    "                .when(df_user.age.between(25, 35), \"25-35\")\n",
    "                .when(df_user.age.between(36, 50), \"36-50\")\n",
    "                .when(df_user.age > 50, \"+50\")\n",
    "                .otherwise(\"Unknown\"))\n",
    "\n",
    "df_category_count_by_age = df_user_with_age_group.groupBy(\"age_group\", \"category\") \\\n",
    "    .agg(count(\"*\").alias(\"category_count\")) \\\n",
    "    .groupBy(\"age_group\") \\\n",
    "    .agg(max(struct(\"category_count\", \"category\")).alias(\"max_count\")) \\\n",
    "    .select(\"age_group\", \"max_count.category\", \"max_count.category_count\") \\\n",
    "\n",
    "df_category_count_by_age.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5. Find the median follower count for different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import percentile_approx\n",
    "\n",
    "df_median_follower_count_by_age = df_user_with_age_group.groupBy(\"age_group\") \\\n",
    "    .agg(percentile_approx(\"follower_count\", 0.5, lit(1000000)).alias(\"median_follower_count\")) \\\n",
    "    .select(\"age_group\", \"median_follower_count\")\n",
    "\n",
    "df_median_follower_count_by_age.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 6. Find how many users have joined each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_geo_joined = df_user.join(df_geo, on='ind') \\\n",
    "    .select(year('timestamp').alias('post_year'), 'date_joined') \\\n",
    "    .where(\"year(timestamp) between 2015 and 2020\")\n",
    "\n",
    "df_users_joined_by_year = df_user_geo_joined.groupBy(\"post_year\") \\\n",
    "    .agg(count(\"*\").alias(\"number_users_joined\"))\n",
    "\n",
    "df_users_joined_by_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 7. Find the median follower count of users based on their joining year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter users who joined between 2015 and 2020\n",
    "df_user_joined = df_user.filter(df_user.date_joined.between('2015-01-01', '2020-12-31'))\n",
    "\n",
    "# extract the year from the timestamp column in the df_geo table\n",
    "df_geo_year = df_geo.withColumn(\"post_year\", year(\"timestamp\"))\n",
    "\n",
    "# join df_user_joined with df_geo_year and df_pin to get follower count for each user\n",
    "df_join_pin = df_user_joined.join(df_geo_year, on=\"ind\").join(df_pin, on=\"ind\")\n",
    "\n",
    "# calculate the median follower count for each year\n",
    "df_median_followers_by_post_year = df_join_pin.groupBy(\"post_year\").agg(percentile_approx(\"follower_count\", 0.5, lit(1000000)).alias(\"median_follower_count\"))\n",
    "\n",
    "# display the results\n",
    "df_median_followers_by_post_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8. Find the median follow count of users based on their joining year and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter users joined between 2015 and 2020\n",
    "df_user_filtered = df_user.filter((df_user.date_joined >= \"2015-01-01\") & (df_user.date_joined < \"2021-01-01\"))\n",
    "\n",
    "# Join the required dataframes\n",
    "df_join2 = df_pin.join(df_user_filtered, on = \"ind\").join(df_geo.select(\"ind\", year(\"timestamp\").alias(\"post_year\")), on=\"ind\").join(df_user_with_age_group.select(\"age_group\", \"ind\"), on=\"ind\")\n",
    "\n",
    "# Calculate the median follower count by age group and post year\n",
    "df_median_follower_by_year_joined = df_join2.groupBy(\"age_group\", \"post_year\").agg(percentile_approx(\"follower_count\", 0.5, lit(1000000)).alias(\"median_follower_count\"))\n",
    "\n",
    "# Print the results\n",
    "df_median_follower_by_year_joined.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
